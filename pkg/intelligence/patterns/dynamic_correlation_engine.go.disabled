package patterns

import (
	"context"
	"sync"
	"time"

	"github.com/yairfalse/tapio/pkg/domain"
	"go.uber.org/zap"
)

// DynamicCorrelationEngine learns correlations from live events
type DynamicCorrelationEngine struct {
	logger *zap.Logger

	// Learning components
	sequenceLearner   *SequenceLearner
	temporalAnalyzer  *TemporalAnalyzer
	causalityDetector *CausalityDetector
	anomalyCorrelator *AnomalyCorrelator

	// Live correlation state
	activeCorrelations map[string]*LiveCorrelation
	correlationGraph   *CorrelationGraph

	// Learning parameters
	config LearningConfig
	mu     sync.RWMutex
}

// LiveCorrelation represents a correlation being learned
type LiveCorrelation struct {
	ID               string
	Type             string // sequence, temporal, causal, spatial
	Confidence       float64
	ObservationCount int
	FirstSeen        time.Time
	LastSeen         time.Time

	// The actual correlation rule being learned
	Rule CorrelationRule

	// Statistical tracking
	Stats CorrelationStats
}

// CorrelationRule defines what events correlate and how
type CorrelationRule struct {
	// Conditions that identify correlated events
	EventA EventMatcher
	EventB EventMatcher

	// Relationship between events
	Relationship RelationshipType

	// Learned parameters
	TimeWindow  time.Duration
	Probability float64
	Direction   string // A→B, B→A, A↔B
}

// EventMatcher identifies events dynamically
type EventMatcher struct {
	// Dynamic matching based on observed patterns
	Attributes map[string]interface{}

	// Learned importance weights
	Weights map[string]float64

	// Flexible matching function
	MatchFunc func(*domain.UnifiedEvent) float64
}

// RelationshipType describes how events relate
type RelationshipType string

const (
	RelCausal      RelationshipType = "causal"      // A causes B
	RelTemporal    RelationshipType = "temporal"    // A happens before B
	RelSpatial     RelationshipType = "spatial"     // A and B on same entity
	RelStatistical RelationshipType = "statistical" // A and B co-occur
)

// Process learns from a stream of events
func (e *DynamicCorrelationEngine) Process(ctx context.Context, event *domain.UnifiedEvent) {
	// 1. Update active sequences
	e.sequenceLearner.ObserveEvent(event)

	// 2. Detect temporal patterns
	e.temporalAnalyzer.AnalyzeEvent(event)

	// 3. Build causality graph
	e.causalityDetector.UpdateGraph(event)

	// 4. Find anomaly correlations
	e.anomalyCorrelator.CheckEvent(event)

	// 5. Merge findings into live correlations
	e.updateLiveCorrelations(event)
}

// GetCorrelations returns learned correlations for an event
func (e *DynamicCorrelationEngine) GetCorrelations(event *domain.UnifiedEvent) []CorrelationResult {
	e.mu.RLock()
	defer e.mu.RUnlock()

	var results []CorrelationResult

	// Check each live correlation
	for _, correlation := range e.activeCorrelations {
		if score := e.matchCorrelation(event, correlation); score > 0 {
			results = append(results, CorrelationResult{
				CorrelationID: correlation.ID,
				Type:          correlation.Type,
				Score:         score * correlation.Confidence,
				Rule:          correlation.Rule,
				Explanation:   e.explainCorrelation(event, correlation),
			})
		}
	}

	return results
}

// SequenceLearner learns event sequences
type SequenceLearner struct {
	// Suffix tree for sequence mining
	sequenceTree *SuffixTree

	// Active sequences being tracked
	activeSequences map[string]*EventSequence

	// Learned sequence patterns
	patterns map[string]*SequencePattern
}

// ObserveEvent updates sequence learning
func (s *SequenceLearner) ObserveEvent(event *domain.UnifiedEvent) {
	// 1. Add to suffix tree
	s.sequenceTree.Add(event)

	// 2. Check if event continues any active sequences
	for key, seq := range s.activeSequences {
		if seq.CouldFollow(event) {
			seq.Add(event)

			// Check if sequence is now significant
			if seq.IsSignificant() {
				pattern := s.createPattern(seq)
				s.patterns[pattern.ID] = pattern
			}
		}
	}

	// 3. Start new sequences
	newSeq := NewEventSequence(event)
	s.activeSequences[newSeq.ID] = newSeq

	// 4. Prune old sequences
	s.pruneOldSequences()
}

// TemporalAnalyzer finds time-based correlations
type TemporalAnalyzer struct {
	// Time series analysis
	timeSeries map[string]*TimeSeries

	// Periodic pattern detection
	periodicPatterns map[string]*PeriodicPattern

	// Time-based correlation matrix
	correlationMatrix *TimeCorrelationMatrix
}

// CausalityDetector builds causal graphs
type CausalityDetector struct {
	// Directed graph of causal relationships
	causalGraph *DirectedGraph

	// Statistical tests for causality
	grangerTest *GrangerCausalityTest

	// Intervention detection
	interventions map[string]*Intervention
}

// THE KEY INSIGHT: Let the system discover its own patterns!

// Example of discovered correlation:
func ExampleDiscoveredCorrelation() *LiveCorrelation {
	return &LiveCorrelation{
		ID:               "auto-discovered-001",
		Type:             "causal",
		Confidence:       0.92,
		ObservationCount: 1547,

		Rule: CorrelationRule{
			EventA: EventMatcher{
				Attributes: map[string]interface{}{
					"type":  "network",
					"error": "connection_refused",
					"port":  "3306",
				},
				MatchFunc: func(e *domain.UnifiedEvent) float64 {
					// Learned: MySQL connection failures
					if e.Network != nil && e.Network.DestPort == 3306 {
						return 0.9
					}
					return 0
				},
			},
			EventB: EventMatcher{
				Attributes: map[string]interface{}{
					"type":   "pod",
					"reason": "CrashLoopBackOff",
					"label":  "app=api",
				},
				MatchFunc: func(e *domain.UnifiedEvent) float64 {
					// Learned: API pods crash after DB issues
					if e.Kubernetes != nil && e.Kubernetes.Reason == "CrashLoopBackOff" {
						return 0.85
					}
					return 0
				},
			},
			Relationship: RelCausal,
			TimeWindow:   30 * time.Second,
			Probability:  0.87,
			Direction:    "A→B",
		},

		Stats: CorrelationStats{
			TruePositives:  1423,
			FalsePositives: 124,
			Precision:      0.92,
			Recall:         0.88,
		},
	}
}

// Self-Organizing Correlation Discovery
type CorrelationDiscoveryPipeline struct {
	// Stage 1: Event Stream Analysis
	streamAnalyzer *StreamAnalyzer

	// Stage 2: Pattern Mining
	patternMiner *UnsupervisedPatternMiner

	// Stage 3: Correlation Hypothesis Generation
	hypothesisGen *HypothesisGenerator

	// Stage 4: Hypothesis Testing
	tester *StatisticalTester

	// Stage 5: Correlation Refinement
	refiner *CorrelationRefiner
}

// The magic happens here - no human intervention needed!
func (p *CorrelationDiscoveryPipeline) DiscoverCorrelations(events []*domain.UnifiedEvent) []*LiveCorrelation {
	// 1. Analyze event stream for patterns
	streams := p.streamAnalyzer.SegmentStream(events)

	// 2. Mine patterns without supervision
	patterns := p.patternMiner.MinePatterns(streams)

	// 3. Generate correlation hypotheses
	hypotheses := p.hypothesisGen.GenerateHypotheses(patterns)

	// 4. Test hypotheses statistically
	validated := p.tester.TestHypotheses(hypotheses, events)

	// 5. Refine and optimize correlations
	correlations := p.refiner.RefineCorrelations(validated)

	return correlations
}

// Real Example: System discovers "Friday Deploy Curse"
func FridayDeployCurseExample() *LiveCorrelation {
	return &LiveCorrelation{
		ID:         "temporal-deploy-risk-001",
		Type:       "temporal-statistical",
		Confidence: 0.78,

		Rule: CorrelationRule{
			EventA: EventMatcher{
				Attributes: map[string]interface{}{
					"day_of_week": "Friday",
					"hour_range":  "14:00-17:00",
					"event_type":  "deployment",
				},
			},
			EventB: EventMatcher{
				Attributes: map[string]interface{}{
					"severity":   "high",
					"time_delta": "+2h to +72h",
					"category":   "incident",
				},
			},
			Relationship: RelStatistical,
			Probability:  0.78, // 78% of Friday afternoon deploys cause issues!
		},
	}
}

// Correlation Learning from K8s Native Structure
func (e *DynamicCorrelationEngine) LearnFromK8sStructure() {
	// The brilliant part: K8s already tells us correlations!

	// 1. Owner References = Causal correlation
	// 2. Selectors = Spatial correlation
	// 3. Events = Temporal correlation
	// 4. Conditions = State correlation

	// We just need to observe and learn the patterns!
}

// No more static patterns - the system learns what matters!
type AdaptiveCorrelation struct {
	// Changes over time based on observations
	CurrentRule CorrelationRule
	RuleHistory []CorrelationRule

	// Adapts to environment changes
	EnvironmentFactors map[string]float64

	// Feedback loop from users
	UserFeedback []FeedbackEvent
}

// updateLiveCorrelations merges findings from all learners
func (e *DynamicCorrelationEngine) updateLiveCorrelations(event *domain.UnifiedEvent) {
	e.mu.Lock()
	defer e.mu.Unlock()

	// Get findings from each learner
	sequenceFindings := e.sequenceLearner.GetFindings()
	temporalFindings := e.temporalAnalyzer.GetFindings()
	causalFindings := e.causalityDetector.GetFindings()

	// Merge and update correlations
	for _, finding := range append(append(sequenceFindings, temporalFindings...), causalFindings...) {
		if existing, ok := e.activeCorrelations[finding.ID]; ok {
			// Update existing correlation
			existing.ObservationCount++
			existing.LastSeen = time.Now()
			existing.Confidence = e.updateConfidence(existing, finding)
		} else {
			// New correlation discovered!
			e.activeCorrelations[finding.ID] = finding
			e.logger.Info("New correlation discovered",
				zap.String("id", finding.ID),
				zap.String("type", finding.Type),
				zap.Float64("confidence", finding.Confidence))
		}
	}
}

// The system becomes smarter over time!
func (e *DynamicCorrelationEngine) GetIntelligenceLevel() string {
	totalCorrelations := len(e.activeCorrelations)
	avgConfidence := e.calculateAverageConfidence()

	switch {
	case totalCorrelations < 10:
		return "Learning basics..."
	case totalCorrelations < 100 && avgConfidence < 0.7:
		return "Building knowledge..."
	case totalCorrelations < 1000 && avgConfidence < 0.85:
		return "Getting smarter..."
	case totalCorrelations >= 1000 && avgConfidence >= 0.85:
		return "Expert system!"
	default:
		return "Evolving..."
	}
}
